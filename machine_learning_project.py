# -*- coding: utf-8 -*-
"""machine-learning-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/155GR-m6_lcIN1UsOZJw6GLxjBb2g-q36

# Santander Customer Transaction Prediction

![](https://storage.googleapis.com/kaggle-media/competitions/santander/atm_image.png)

Importing and installing jovian, so that I can save my work whenever I need
"""

!pip install jovian --upgrade --quiet

!pip install jovian --upgrade --quiet  # Re-install jovian after kernel restart

import jovian  # Now the import should work

"""Installing some other essential libraries for the project"""

#restart the kernel after installation
!pip install numpy pandas-profiling matplotlib seaborn --quiet

!pip install jovian opendatasets xgboost graphviz lightgbm scikit-learn xgboost lightgbm --upgrade --quiet

# Commented out IPython magic to ensure Python compatibility.
import opendatasets as od
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
import sys
import warnings
warnings.filterwarnings("ignore")
import os
# %matplotlib inline

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 150)
sns.set_style('darkgrid')
matplotlib.rcParams['font.size'] = 14
matplotlib.rcParams['figure.figsize'] = (10, 6)
matplotlib.rcParams['figure.facecolor'] = '#00000000'

"""## Problem Statement

> At Santander our mission is to help people and businesses prosper. We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals.

> Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?

> In this challenge, we need to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem.

> View and download the data here: https://www.kaggle.com/competitions/santander-customer-transaction-prediction/data

## Downloading the Data

We can download the dataset from Kaggle directly within the Jupyter notebook using the `opendatasets` library. Make sure to [accept the competition rules](https://www.kaggle.com/competitions/santander-customer-transaction-prediction/rules) before executing the following cell.
"""

od.download('https://www.kaggle.com/competitions/santander-customer-transaction-prediction')

import numpy as np

os.listdir('santander-customer-transaction-prediction')

"""#### Training Set

> For making to see the whole notebook at a fast pace, I selected some columns who are having the greater importances than others. I have taken 80k rows and 26 columns, as I tried earlier taking all the columns and observed over 20 mins kernel running on some cells individually.

> I also changed the data type from float 64 to float 16 so that every cell runs smoothly and instantaneously.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# df_dtype = {}
# df_columns = ['target','var_81','var_12','var_53','var_139','var_99','var_170','var_146','var_44','var_80','var_166','var_177','var_6','var_174','var_110','var_26','var_109','var_198','var_190','var_22','var_21','var_133','var_148','var_179','var_0','var_86']
# for name in df_columns:
#     df_dtype[name] = np.float16
# 
# train_df = pd.read_csv('./santander-customer-transaction-prediction/train.csv', dtype=df_dtype, nrows = 80000, usecols = df_columns)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_df = pd.read_csv('./santander-customer-transaction-prediction/test.csv')
# test_df

# Execute this to save new versions of the notebook
jovian.commit(project="machine-learning-project")

"""### Preprocessing and Data Analysis

Let's take a look at the available columns, and figure out if we can create new columns or apply any useful transformations.

### Training Data Frame
"""

train_df.sample(20)

train_df.shape

"""There are 26 columns and 80000 rows in the training set."""

train_df.info()

train_df.isnull().sum().sum()

"""It is great to figure out that we don't need to deal with Nan elements in the training set"""

train_df.describe()

target_values = train_df.target.value_counts()
target_values

sns.countplot(train_df.target);

"""With the help of above plot, we can clearly observe that target having value 0 is more than seven times the value of target equals to 1.

### Test Data Frame
"""

test_df.sample(20)

test_df.shape

"""Test set is having one column less than the training set which is obviously the target column. Which  we are going to predict"""

test_df.info()

test_df.describe()

test_df.isnull().sum().sum()

"""### Input and Target Columns
Let's select the columns that we'll use for training.
"""

target_cols = 'target'
input_cols =  ['var_81','var_12','var_53','var_139','var_99','var_170','var_146','var_44','var_80','var_166','var_177','var_6','var_174','var_110','var_26','var_109','var_198','var_190','var_22','var_21','var_133','var_148','var_179','var_0','var_86']

"""#### Making Validation and Training Set"""

from sklearn.model_selection import train_test_split

# Commented out IPython magic to ensure Python compatibility.
# %%time
# X_train, X_val = train_test_split(train_df, test_size=0.2, random_state=42)

X_train

X_val

"""#### Scaling the training and validation data"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler().fit(train_df[input_cols])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# X_train[input_cols] = scaler.transform(X_train[input_cols])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# X_val[input_cols] = scaler.transform(X_val[input_cols])

"""#### Accuracy score

Let's import accuracy_score for checking the accuracies of our models.
"""

from sklearn.metrics import accuracy_score

"""#### Lets try some random guesses on training and validation set"""

def random_guess(inputs):
    return np.random.choice([0, 1], len(inputs))

accuracy_score(X_train[target_cols], random_guess(X_train[input_cols]))

accuracy_score(X_val[target_cols], random_guess(X_val[input_cols]))

"""As expected, accuracy score is about 50% for a model which will guess randomly.

### Logistic Regression

Logistic regression is a commonly used technique for solving binary classification problems. In a logistic regression model:

> we take linear combination (or weighted sum of the input features)

> we apply the sigmoid function to the result to obtain a number between 0 and 1

> this number represents the probability of the input being classified as "Yes"

> Instead of RMSE, the accuracy score is used to evaluate the results
"""

from sklearn.linear_model import LogisticRegression

"""Let's train the model with some hyperparamters at the start."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = LogisticRegression(n_jobs = -1, random_state = 42).fit(X_train[input_cols], X_train[target_cols])

"""predicting value of our model on training set."""

preds_train = model.predict(X_train[input_cols])
preds_train

"""predicting value of our model on validation set."""

preds_val = model. predict(X_val[input_cols])

"""lets have a look at the accuracy score as well."""

accuracy_score(preds_train, X_train[target_cols])

accuracy_score(preds_val, X_val[target_cols])

"""Current accuracy score on validation set is 0.89975 which looks like a satisfactory result. Let's try whether we can make it more better

Let's find out the value of weights and value of intercept of above model
"""

print(model.coef_.tolist())

print(model.intercept_)

"""### Hyperparameters Tuning

We don't have many useful parameters which can be used with the default logistic regression model. But, still let's try to do something crazy with the model.
"""

def test_params_lr(**params):
    model = LogisticRegression(n_jobs=-1, random_state=42, **params)
    model.fit(X_train[input_cols], X_train[target_cols])
    a1 = model.predict(X_train[input_cols])
    b1 = model.predict(X_val[input_cols])
    train_acs = accuracy_score(X_train[target_cols], a1)
    val_acs = accuracy_score(X_val[target_cols], b1)
    print('Train Accuracy Score: {}, Validation Accuracy Score: {}'.format(train_acs, val_acs))

test_params_lr()

"""##### Solver"""

test_params_lr(solver = 'liblinear')

"""Accuracy score is same on validation set and almost similar on training set"""

test_params_lr(solver = 'sag')

test_params_lr(solver = 'saga')

test_params_lr(solver = 'newton-cg')

"""All the solvers are giving us almost the same value of accuracy score on training set and exactly same score on validation set.

##### multi_class

test_params(multi_class = 'auto')
"""

test_params_lr(multi_class = 'ovr')

test_params_lr(multi_class = 'multinomial')

"""Again, multi_class parameter hasn't given us any significant change in the accuracy score.

##### max_iter
"""

test_params_lr(max_iter = 50)

test_params_lr(max_iter = 150)

test_params_lr(max_iter = 1000)

"""After changing values of max_iter has also not given us any significant change

##### penalty
"""

test_params_lr(solver = 'liblinear', penalty = 'l1')

test_params_lr(solver = 'saga', penalty = 'elasticnet', l1_ratio = 0.4)

test_params_lr( penalty = 'none')

"""penalty is also not able to help us

So, we'll go with our default model with solver = 'lbfgs' and other parameters also equals to their default value. With default model we got the best accuracy score. The best accuracy score is again shown on the next cell.
"""

test_params_lr()

"""#### Gradient Boosting
We're now ready to train our gradient boosting machine (GBM) model. Here's how a GBM model works:

>1) The average value of the target column and uses as an initial prediction every input.

>2) The residuals (difference) of the predictions with the targets are computed.

>3) A decision tree of limited depth is trained to predict just the residuals for each input.

>4) Predictions from the decision tree are scaled using a parameter called the learning rate (this prevents overfitting)

>5) Scaled predictions fro the tree are added to the previous predictions to obtain the new and improved predictions.

>6) Steps 2 to 5 are repeated to create new decision trees, each of which is trained to predict just the residuals from the previous prediction.

The term "gradient" refers to the fact that each decision tree is trained with the purpose of reducing the loss from the previous iteration (similar to gradient descent). The term "boosting" refers the general technique of training new models to improve the results of an existing model.

Importing XGBClassifier from xgboost
"""

from xgboost import XGBClassifier

"""setting some hyperparameters"""

model = XGBClassifier(random_state = 42, n_jobs = -1)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model.fit(X_train[input_cols], X_train[target_cols])

"""predicting the target values and accuracy score of model on training set."""

preds = model.predict(X_train[input_cols])

accuracy_score(preds, X_train.target)

"""#### Importances of different features"""

importance_df = pd.DataFrame({
    'feature': X_train[input_cols].columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

imp_small_part = importance_df.head(10)
imp_small_part

plt.title('Feature Importance')
sns.barplot(data = imp_small_part,x = 'feature', y = 'importance');

"""With the help of above plot, we can say that var_12 and var_81 are the most important features and other features are also trailing behind with a very minute margin.

#### Making prediction on validation set
"""

preds_val = model.predict(X_val[input_cols])

accuracy_score(preds_val,X_val.target)

"""Current accuracy score on validation set is 0.8965625 without the tuning of hyperparameters

### Hyperparameters Tuning

#### Lets define a function for finding out best value for max_depth_error.
"""

def max_depth_error(md):
    model = XGBClassifier(max_depth=md, random_state=42)
    model.fit(X_train[input_cols], X_train[target_cols])
    preds_train = model.predict(X_train[input_cols])
    preds_val = model.predict(X_val[input_cols])
    acs_train = accuracy_score(preds_train,X_train[target_cols])
    acs_val = accuracy_score(preds_val,X_val[target_cols])
    return {'Max Depth': md, 'Training Accuracy Score': acs_train, 'Validation Accuracy Score': acs_val}

# Commented out IPython magic to ensure Python compatibility.
# %%time
# errors_df = pd.DataFrame([max_depth_error(md) for md in range(1, 11)])

errors_df

"""With the help of above data frame, we can select max_depth = 5

We just saw how a function helped us to find out the value of max_depth.
So, Lets define a function which will take care of more than 1 hyperparameter in a single line of code.
"""

def test_params(**params):
    model = XGBClassifier(n_jobs=-1, random_state=42, **params)
    model.fit(X_train[input_cols], X_train[target_cols])
    train_acs = accuracy_score(model.predict(X_train[input_cols]), X_train[target_cols])
    val_acs = accuracy_score(model.predict(X_val[input_cols]), X_val[target_cols])
    print('Training Accuracy Score : {}, Validation Accuracy Score: {}'.format(train_acs, val_acs))

"""#### Trying to find out best learning rate"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.01, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.1, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.15, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.20, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.3, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.5, max_depth = 4)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.7, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.9, max_depth = 4)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.99, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.05, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.12, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.08, max_depth = 5)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_params(learning_rate = 0.09, max_depth = 5)

"""With the help of above brute force technique to find out the best value of learning rate, we got learning_rate = 0.1

#### Trying to find out best n_estimator
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# errors_df = pd.DataFrame([test_params(n_estimators = md, learning_rate = 0.1, max_depth = 4) for md in range(10, 251, 30)])

test_params(n_estimators = 130, learning_rate = 0.09, max_depth = 5)

test_params(n_estimators = 120, learning_rate = 0.09, max_depth = 5)

test_params(n_estimators = 140, learning_rate = 0.09, max_depth = 5)

test_params(n_estimators = 110, learning_rate = 0.09, max_depth = 5)

test_params(n_estimators = 100, learning_rate = 0.09, max_depth = 5)

test_params(n_estimators = 115, learning_rate = 0.09, max_depth = 5)

"""We can clearly observe from above 10 cells that best value for n_estimators is 120 for getting the lowest value of rmse of validation set.

#### Lets also try booster = gbliner
"""

test_params(booster='gblinear')

"""## Model with Best Parameters"""

test_params(n_estimators = 120, learning_rate = 0.09, max_depth = 5)

"""**Accuracy Score on validation set is 0.9014375 with our best model** and above model is the best model out of the many models we tried by changing values of many hyperparameters in both Logistic Regression as well as in XGBoost.

### Summary

> I first downloaded the dataset with the help of opendatasets and used some hyperparamters while reading the train.csv so that the model runs instantaneously without taking much time.

> I used Logistic Regression as our first model, and also changed some parameters but changing the values of hyperparameters only disappointed us, as it didn't give a significant change in the values of rmse and accuracy score

> As my Second Model, I took XGBoost for predicting the target value. I also changed some hyperparameters and at the last also shown the best value of accuracy score with the best model after changing some parameters

### References:

> https://jovian.ai/learn/machine-learning-with-python-zero-to-gbms/lesson/logistic-regression-for-classification

> https://jovian.ai/learn/machine-learning-with-python-zero-to-gbms/lesson/gradient-boosting-with-xgboost


### Ideas for Future Work

> With a better cpu or a good gpu, we can also take more columns and rows from train.csv. And with more data, probably rmse value will may get better
"""

# Execute this to save new versions of the notebook
jovian.commit(project="machine-learning-project")

